<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="xuzichao03@gmail.com"><title>New一个golang爬虫 · ChaoChao</title><meta name="description" content="刚好七八双月结束，工作整理完毕，下个双月OKR还没开始。做久了IOS开发也来扩展下领域，抽空几天学了下Golang，实现一个爬虫。

一、知识要点1、爬虫1.1 工作方式传统爬虫从一个或若干初始网页的URL开始，获得初始网页上的URL，在抓取网页的过程中，不断从当前页面上抽取新的URL放入队列,直到"><meta name="keywords" content="开发者,程序猿,编程,用户体验,产品,IOS,UI,UE,视觉设计,FE,Golang"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/blog_style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/avatar.png"><h3 title=""><a href="/">ChaoChao</a></h3><div class="description"><p>「 About life and code 」</p></div></div></div><ul class="social-links"></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>New一个golang爬虫</a></h3></div><div class="post-content"><blockquote>
<p>刚好七八双月结束，工作整理完毕，下个双月OKR还没开始。做久了IOS开发也来扩展下领域，抽空几天学了下Golang，实现一个爬虫。</p>
</blockquote>
<h2 id="一、知识要点"><a href="#一、知识要点" class="headerlink" title="一、知识要点"></a>一、知识要点</h2><h3 id="1、爬虫"><a href="#1、爬虫" class="headerlink" title="1、爬虫"></a>1、爬虫</h3><h4 id="1-1-工作方式"><a href="#1-1-工作方式" class="headerlink" title="1.1 工作方式"></a>1.1 工作方式</h4><p>传统爬虫从一个或若干初始网页的URL开始，获得初始网页上的URL，在抓取网页的过程中，不断从当前页面上抽取新的URL放入队列,直到满足系统的一定停止条件。聚焦爬虫的工作流程较为复杂，需要根据一定的网页分析算法过滤与主题无关的链接，保留有用的链接并将其放入等待抓取的URL队列。然后，它将根据一定的搜索策略从队列中选择下一步要抓取的网页URL，并重复上述过程，直到达到系统的某一条件时停止。另外，所有被爬虫抓取的网页将会被系统存贮，进行一定的分析、过滤，并建立索引，以便之后的查询和检索；对于聚焦爬虫来说，这一过程所得到的分析结果还可能对以后的抓取过程给出反馈和指导。</p>
<h4 id="1-2-分类"><a href="#1-2-分类" class="headerlink" title="1.2 分类"></a>1.2 分类</h4><ul>
<li>全网爬虫，爬行对象从一些种子 URL 扩充到整个 Web，主要为门户站点搜索引擎和大型 Web 服务提供商采集数据。</li>
<li>聚焦网络爬虫，是指选择性地爬行那些与预先定义好的主题相关页面的网络爬虫。</li>
<li>增量式网络爬虫，是指对已下载网页采取增量式更新和只爬行新产生的或者已经发生变化网页的爬虫，它能够在一定程度上保证所爬行的页面是尽可能新的页面。</li>
<li>Deep Web 爬虫，表层网页是指传统搜索引擎可以索引的页面，以超链接可以到达的静态网页为主构成的Web页面。Deep Web 是那些大部分内容不能通过静态链接获取的、隐藏在搜索表单后的，只有用户提交一些关键词才能获得的 Web 页面。</li>
</ul>
<h4 id="1-3爬虫算法"><a href="#1-3爬虫算法" class="headerlink" title="1.3爬虫算法"></a>1.3爬虫算法</h4><ul>
<li><p>深度优先策略</p>
<p>  其基本方法是按照深度由低到高的顺序，依次访问下一级网页链接，直到不能再深入为止。 爬虫在完成一个爬行分支后返回到上一链接节点进一步搜索其它链接。 当所有链接遍历完后，爬行任务结束。 这种策略比较适合垂直搜索或站内搜索， 但爬行页面内容层次较深的站点时会造成资源的巨大浪费。</p>
</li>
<li><p>广度优先策略</p>
<p>  此策略按照网页内容目录层次深浅来爬行页面，处于较浅目录层次的页面首先被爬行。 当同一层次中的页面爬行完毕后，爬虫再深入下一层继续爬行。 这种策略能够有效控制页面的爬行深度，避免遇到一个无穷深层分支时无法结束爬行的问题，实现方便，无需存储大量中间节点，不足之处在于需较长时间才能爬行到目录层次较深的页面</p>
</li>
</ul>
<h3 id="2、golang"><a href="#2、golang" class="headerlink" title="2、golang"></a>2、golang</h3><h4 id="2-1-语法学习"><a href="#2-1-语法学习" class="headerlink" title="2.1 语法学习"></a>2.1 语法学习</h4><ul>
<li><p>为了让学习更加快速，想要优先上手，而不是沉浸在大量语法里面，找了一遍基础的语法文档，直接全读整体语法，先有个基础但是全面的认识。<br><a href="http://www.runoob.com/go/go-tutorial.html" target="_blank" rel="external">语法教程链接</a></p>
</li>
<li><p>然后直接手一本web教程书籍，此本书籍是开源的，在github上有1.78万star，5年前就开始书写，一直被追捧和使用。<a href="https://github.com/astaxie/build-web-application-with-golang" target="_blank" rel="external">书籍链接</a></p>
</li>
</ul>
<h3 id="2-2-环境安装"><a href="#2-2-环境安装" class="headerlink" title="2.2 环境安装"></a>2.2 环境安装</h3><h4 id="1-1-在MacOSX上安装"><a href="#1-1-在MacOSX上安装" class="headerlink" title="1.1 在MacOSX上安装"></a>1.1 在MacOSX上安装</h4><ul>
<li><a href="https://golang.org/dl/" target="_blank" rel="external">下载地址</a></li>
<li>源码包：go1.4.linux-amd64.tar.gz。</li>
<li>将下载的源码包解压至 /usr/local目录。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tar -C /usr/local -xzf go1.4.linux-amd64.tar.gz</div></pre></td></tr></table></figure>
<ul>
<li>将 /usr/local/go/bin 目录添加至PATH环境变量：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export PATH=$PATH:/usr/local/go/bin</div></pre></td></tr></table></figure>
<ul>
<li>注意：MAC 系统下你可以使用 .pkg 结尾的安装包直接双击来完成安装，安装目录在 /usr/local/go/ 下。</li>
</ul>
<h4 id="1-2-其他方式"><a href="#1-2-其他方式" class="headerlink" title="1.2 其他方式"></a>1.2 其他方式</h4><p><a href="https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/01.1.md" target="_blank" rel="external">参考链接</a></p>
<h2 id="二、代码实现"><a href="#二、代码实现" class="headerlink" title="二、代码实现"></a>二、代码实现</h2><p>先确立一个小目标，就是我们要爬取的网页的数据源是什么。一直觉得国内的大学排名争议比较有趣，TOP2的两所，但是TOP5的有8所，TOP10的有20所，哈哈，所以来爬个大学排行榜玩玩吧。</p>
<h3 id="1、网页抓取"><a href="#1、网页抓取" class="headerlink" title="1、网页抓取"></a>1、网页抓取</h3><h3 id="1-1-定义一个学校"><a href="#1-1-定义一个学校" class="headerlink" title="1.1 定义一个学校"></a>1.1 定义一个学校</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">type SchoolObj struct &#123;</div><div class="line">	rankTypeName string</div><div class="line">	RankIndex int</div><div class="line">	SchoolName string</div><div class="line">	EnrollOrder string</div><div class="line">	StarLevel string</div><div class="line">	LocationName string</div><div class="line">	SchoolType  string</div><div class="line">	UrlAddress string</div><div class="line">	SchoolTags []string</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="1-2-单页面html解析"><a href="#1-2-单页面html解析" class="headerlink" title="1.2 单页面html解析"></a>1.2 单页面html解析</h3><ul>
<li><p>引入go语言的http函数包和上面定义的学校结构题</p>
</li>
<li><p>发起一个网页请求返回，go语言会返回网页的<html>以下全部的html格式字符串</html></p>
</li>
<li><p>如何从这些字符串中遍历查找和解析出我们需要的学校排名字段？</p>
</li>
</ul>
<p>因为有过前端开发的经验，我自然而然想到，使用CSS选择器会比直接使用遍历算法来得高效，有CSS的选择规则，我可以批量规律的获取和处理HTML的DOM结构数据。端开发中的jQuery提供了方便的操作 DOM 的 API。使用 Go 语言做服务器端开发，有时候需要解析 HTML 文件，比如抓取网站内容、写一个爬虫等。这时候如果有一个类似 jQuery 的库可以使用，操作 DOM 会很方便，而且，上手也会很快。果然，还真有这样的工具，此处推荐一个GitHub的开源框架 — Goquery 。</p>
<p>A、使用介绍：</p>
<p>goquery定义了一个Document结构，直接对应网页Javascript的Document节点，通过一个NewDocument方法，传入参数地址为网页的url地址，直接生产一个虚拟的go语言上的dom。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">type Document struct &#123;</div><div class="line">	*Selection</div><div class="line">	Url      *url.URL</div><div class="line">	rootNode *html.Node</div><div class="line">&#125;</div><div class="line"></div><div class="line">func NewDocument(url string) (*Document, error) &#123;</div><div class="line">	// Load the URL</div><div class="line">	res, e := http.Get(url)</div><div class="line">	if e != nil &#123;</div><div class="line">		return nil, e</div><div class="line">	&#125;</div><div class="line">	return NewDocumentFromResponse(res)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Document有定义find方法，方法的使用和JQuery里面一直，传入目标字符串的css选择器即可。通过对Document执行find查找方法，获得全部学校目标的字符串数组。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">doc.Find(&quot;.bangTable table tr&quot;)</div></pre></td></tr></table></figure>
<p>这里的选择器怎么来的呢，我们在chrome里面打开url地址，找到我们想要收集的数据排名，右键打开审查元素，可以看到HTML的选择器名称。这里需要有一点CSS基础，因为有的选择器不是直接唯一的，需要自己去判断，怎样的选择器组合才能准确的拿到想要的目标字符串。</p>
<p><img src="/assets/images/schoolDom.jpg" alt=""></p>
<p>Document有定义each方法，用于遍历数组，也就是各个大学所对应的dom节点。在each方法中继续使用查找方法，并最后获得想要的字符串。</p>
<p>每一个dom对应一个SchoolStruct，新建并赋值，放入数组中返回。</p>
<p>B、代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">import (</div><div class="line">	&quot;github.com/PuerkitoBio/goquery&quot;</div><div class="line">	&quot;SchoolReptile/struct&quot;</div><div class="line">	&quot;net/http&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func GaokaoquanRank(urlAddress string) []SchoolStruct.SchoolObj &#123;</div><div class="line"></div><div class="line">	var array [] SchoolStruct.SchoolObj</div><div class="line"></div><div class="line">	doc, err := goquery.NewDocument(urlAddress)</div><div class="line">	if err != nil &#123;</div><div class="line">		log.Fatal(err)</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	// Find the review items</div><div class="line">	doc.Find(&quot;.bangTable table tr&quot;).Each(func(i int, s *goquery.Selection) &#123;</div><div class="line">		// For each item found, get the band and title</div><div class="line">		var obj SchoolStruct.SchoolObj</div><div class="line">		obj.RankIndex = s.Find(&quot;.t1 span&quot;).Text()</div><div class="line">		obj.SchoolName = s.Find(&quot;.t2 a&quot;).Text()</div><div class="line">		obj.UrlAddress ,_ = s.Find(&quot;.t2 a&quot;).Attr(&quot;href&quot;)</div><div class="line">		obj.LocationName = s.Find(&quot;.t3&quot;).Text()</div><div class="line">		obj.SchoolType = s.Find(&quot;.t4&quot;).Text()</div><div class="line">		obj.StarLevel = s.Find(&quot;.t5&quot;).Text()</div><div class="line">		obj.EnrollOrder = &quot;本科第一批&quot;</div><div class="line">		array = append(array, obj)</div><div class="line"></div><div class="line">	&#125;)</div><div class="line"></div><div class="line">	return array</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="2、接口请求"><a href="#2、接口请求" class="headerlink" title="2、接口请求"></a>2、接口请求</h3><p>我们再爬去数据的时候，一般都能直接抓取网页数据，但是有的数据在第一页炳辉展示出来，需要有点击操作，比如加载更多。此处的大学排行有200位，第一页请求只有20位，这时候就会发现，接口请求的方便。<br>有的网页在接口上做了cookie校验，摸清别人的请求规则，才能正确模拟出请求获得返回数据。</p>
<p>我们此处拿乐学高考作文例子，获取各个类型的大学排行榜。通过charles代理，我们获得请求的各类参数。</p>
<ul>
<li>拼接请求url</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">url := LexueHost+&quot;/college/ranking?page=&quot;+pageStr+&quot;&amp;rank_type=&quot;+rankObj.RankType+&quot;&amp;page_size=15&quot;</div></pre></td></tr></table></figure>
<ul>
<li><p>发送HTTP请求，获取返回</p>
<p>网络请求返回的是一个字符串结构的数据，我们需要把它映射成map结构好获取key对应的value值。</p>
<p>这里推荐一个go语言在json解析上的一个开源库Simplejson，将返回的数据进行JSON结构化，然后通过get方法可以直接获得对应的参数值。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">defer resp.Body.Close()</div><div class="line"></div><div class="line">data, err := ioutil.ReadAll(resp.Body)</div><div class="line"></div><div class="line">jsonBody,err := simplejson.NewJson(data)</div><div class="line"></div><div class="line">schoolJsonArray,err := jsonBody.Get(&quot;schools&quot;).Array()</div></pre></td></tr></table></figure>
<ul>
<li>多页请求使用递归的方式，不断改变get请求的pageStr参数，pageindex ++ ，当判断请求返回的json为空的时候，则说明接口请求已经到到了最后一页，跳出递归</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">var nextArray [] SchoolStruct.SchoolObj</div><div class="line">nextArray = LexueRankEachList(rankObj,pageIndex)</div></pre></td></tr></table></figure>
<p>B、代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line">import (</div><div class="line">	&quot;SchoolReptile/struct&quot;</div><div class="line">	&quot;net/http&quot;</div><div class="line">	&quot;io/ioutil&quot;</div><div class="line">	&quot;fmt&quot;</div><div class="line">	&quot;bytes&quot;</div><div class="line">	&quot;encoding/json&quot;</div><div class="line">	&quot;strings&quot;</div><div class="line">	&quot;github.com/bitly/go-simplejson&quot;</div><div class="line">	&quot;strconv&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func LexueRankEachList(rankObj SchoolStruct.RankTypeObj,pageIndex int ) []SchoolStruct.SchoolObj &#123;</div><div class="line"></div><div class="line">	pageStr := strconv.Itoa(pageIndex)</div><div class="line"></div><div class="line">	url := LexueHost+&quot;/college/ranking?page=&quot;+pageStr+&quot;&amp;rank_type=&quot;+rankObj.RankType+&quot;&amp;page_size=15&quot;</div><div class="line"></div><div class="line">	resp, err := http.Get(url)</div><div class="line">	if err != nil &#123;</div><div class="line">		// handle error</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	defer resp.Body.Close()</div><div class="line"></div><div class="line">	data, err := ioutil.ReadAll(resp.Body)</div><div class="line"></div><div class="line">	jsonBody,err := simplejson.NewJson(data)</div><div class="line"></div><div class="line">	schoolJsonArray,err := jsonBody.Get(&quot;schools&quot;).Array()</div><div class="line"></div><div class="line">	var array [] SchoolStruct.SchoolObj</div><div class="line"></div><div class="line">	if len(schoolJsonArray) &lt;= 0 &#123;</div><div class="line">		println(&quot;请求到头了&quot;)</div><div class="line">		return array</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	for i,_ := range schoolJsonArray &#123;</div><div class="line">		schoolJson := jsonBody.Get(&quot;schools&quot;).GetIndex(i)</div><div class="line">		var obj SchoolStruct.SchoolObj</div><div class="line">		obj.RankIndex = strconv.Itoa(schoolJson.Get(&quot;school_rank&quot;).MustInt())</div><div class="line">		obj.SchoolName = schoolJson.Get(&quot;school_name&quot;).MustString()</div><div class="line">		obj.SchoolTags = schoolJson.Get(&quot;school_tags&quot;).MustStringArray()</div><div class="line">		array = append(array, obj)</div><div class="line">		println(obj.RankIndex,obj.SchoolName,obj.SchoolTags)</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	pageIndex++</div><div class="line">	var nextArray [] SchoolStruct.SchoolObj</div><div class="line">	nextArray = LexueRankEachList(rankObj,pageIndex)</div><div class="line">	if len(nextArray) &gt; 0 &#123;</div><div class="line">		for _,obj := range nextArray &#123;</div><div class="line">			array = append(array,obj)</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	return array</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3、保存到Excel"><a href="#3、保存到Excel" class="headerlink" title="3、保存到Excel"></a>3、保存到Excel</h3><p>前两部获得了网络数据，并解析生成了对应的SchoolStruct数组，这个时候我们只需要创建excel边。遍历数组，把数组里面的数据字段都存入表格即可,git开源库xlsx能够让我们轻松的创建、查找、赋值Excel表。</p>
<p>代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line">func SaveSchoolRank(schoolArray [] SchoolStruct.SchoolObj,excelName string,sheetName string)  &#123;</div><div class="line"></div><div class="line">	var file *xlsx.File</div><div class="line">	var sheet *xlsx.Sheet</div><div class="line">	var row *xlsx.Row</div><div class="line">	var cell *xlsx.Cell</div><div class="line">	var err error</div><div class="line"></div><div class="line">	file,err = xlsx.OpenFile(excelName + &quot;.xlsx&quot;)</div><div class="line"></div><div class="line">	if err != nil &#123;</div><div class="line">		file = xlsx.NewFile()</div><div class="line">		sheet,err = file.AddSheet(sheetName)</div><div class="line">	&#125; else &#123;</div><div class="line">	   sheet = file.Sheet[sheetName]</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	if err == nil &#123;</div><div class="line"></div><div class="line">		for i := 0; i &lt; len(schoolArray); i++ &#123;</div><div class="line">			obj := schoolArray[i]</div><div class="line"></div><div class="line">			row = sheet.AddRow()</div><div class="line">			cell = row.AddCell()</div><div class="line">			cell.Value = obj.RankIndex</div><div class="line"></div><div class="line">			cell = row.AddCell()</div><div class="line">			cell.Value = obj.SchoolName</div><div class="line"></div><div class="line">			cell = row.AddCell()</div><div class="line">			cell.Value = obj.StarLevel</div><div class="line"></div><div class="line">			cell = row.AddCell()</div><div class="line">			cell.Value = obj.LocationName</div><div class="line"></div><div class="line">			cell = row.AddCell()</div><div class="line">			cell.Value = obj.EnrollOrder</div><div class="line"></div><div class="line">			cell = row.AddCell()</div><div class="line">			cell.Value = obj.SchoolType</div><div class="line"></div><div class="line">			cell = row.AddCell()</div><div class="line">			cell.Value = obj.UrlAddress</div><div class="line"></div><div class="line"></div><div class="line">			var tagStr string</div><div class="line">			for _,value := range obj.SchoolTags &#123;</div><div class="line">				tagStr += &quot;+&quot; + value</div><div class="line">			&#125;</div><div class="line">			cell = row.AddCell()</div><div class="line">			cell.Value = tagStr</div><div class="line"></div><div class="line"></div><div class="line">			if err != nil &#123;</div><div class="line">				fmt.Printf(err.Error())</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">	&#125;</div><div class="line"></div><div class="line">	err = file.Save(excelName + &quot;.xlsx&quot;)</div><div class="line">	if err != nil &#123;</div><div class="line">		fmt.Printf(err.Error())</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-09-01</span><i class="fa fa-tag"></i><a href="/tags/开发/" title="开发" class="tag">开发 </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://zichao.me/2017/09/01/New一个golang爬虫/,ChaoChao,New一个golang爬虫,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="next pagbuttons"><a role="navigation" href="/2017/08/03/如何成功的交付产品/" title="如何成功的交付产品" class="btn">下一篇</a></li></ul></div><a id="comments"></a><div id="youyan_thread" class="post"></div><script>(function() {

    var YYDiv = document.createElement('div');
    YYDiv.id = 'uyan_frame';
    document.getElementById('youyan_thread').appendChild(YYDiv);

    var YYScript = document.createElement('script');
    YYScript.type = 'text/javascript';
    YYScript.async = true;
    YYScript.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//v2.uyan.cc/code/uyan.js?uid=' + '2143349';
    YYScript.charset = 'UTF-8';
    document.getElementById('youyan_thread').appendChild(YYScript);

})();</script></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>